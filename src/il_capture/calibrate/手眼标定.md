# 标定流程

该标定流程不依赖特定的相机型号，适用于所有支持ROS的相机

## 标定前准备
1. 安装ROS和相关依赖包
2. 创建`raw_data/valid`目录创建在`{calibrate}`目录下，并删除其中的所有文件
3. 找到相机的内参文件，获取相机内参文件的路径（为方便后续说明，此处将该路径记为`${camera_intrinsics_path}`）
4. 将`get_chessboard_pos_eular.ipynb`和`valid_test_chessboard.py`中的相机内参路径修改为`${camera_intrinsics_path}`


## 标定步骤

1. **启动相机**
`roslaunch astra_camera astra.launch`
or
`roslaunch realsense2_camera rs_camera.launch`

2. **启动机械臂**
`roslaunch ur_robot_driver ur5_bringup.launch robot_ip:=<robot_ip>`

3. **抓取图像准备**
在`{calibrate}/raw_data`目录下运行
`rosrun image_view image_saver image:=/camera/color/image_raw _save_all_image:=false _filename_format:="frame%04d.png" __name:=image_saver`

4. **抓取图像+机器人末端位姿数据**
在`{calibrate}`目录下运行：
`python save_snapshot.py`
    - 调节机械臂末端姿态，使标定板在相机视野内
    - 按下s键保存当前图像和机械臂末端位姿数据
    - 重复上述步骤，采集15~30组数据，建议采集30组以上数据以提高标定精度
    - 按下q键/ctrl退出程序


5. **从图像中提取标定板位姿**
`get_chessboard_pos_eular.ipynb`
    - 该步骤会检测图像中的棋盘格角点，并可视化检测结果
    - 如果角点位置正确，按Y键保存该图对应的标定板位姿数据，否则按N键跳过该图
    - 重复上述步骤，直到处理完所有图像

6. **手眼标定**
`eye_on_base_calibration.ipynb`
    - 该步骤会计算手眼标定的变换矩阵，并保存为`result_hand_eye.txt`
    - TODO: 将保存文件修改为yaml格式，方便后续使用

7. **验证**
    - `valid_test.py`：这个脚本是将得到的矩阵应用回去，通过计算每一张图对应的棋盘格与机械臂末端的位置关系，来验证手眼标定的准确性。
    - `valid_test_chessboard.py`：这个脚本需要将`save_snapshot.py`中的路径修改：`raw_data`->`raw_data/valid`，`raw_data/robot_poses.csv`->`raw_data/valid/robot_poses.csv`,然后重复步骤1-4，采集一张图片，计算输出图中棋盘格角点在机械臂基坐标系下的位置，然后手动测量该位置，与脚本输出结果进行对比，验证手眼标定的准确性。

##  踩坑合集
1. **亚像素角点检测时，`cv2.cornerSubPix`的搜索窗口需要根据实际情况调整，过大会导致精度下降，过小可能导致搜索失败。建议使用(5,5)的窗口。**
2. 在可视化角点时，使用较小的圆圈和实心填充可以更清晰地显示角点位置，避免视觉干扰。
3. 在验证手眼标定结果时，确保使用正确的变换矩阵，并仔细检查坐标系的一致性
4. 确认所用的图片是否经过畸变校正，避免未矫正或**重复**矫正导致的误差。
