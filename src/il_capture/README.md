## 示教轨迹采集

该功能包提供示教数据采集过程中需要的一些必要内容

示教数据包含：
- 示教器末端位姿
- 末端力传感器数据
- 相机点云数据

该功能包提供以下功能：
- 标定：
    - 相机与机械臂的手眼标定（眼在手外）
    - 机械臂与动作捕捉系统的标定
- 重力补偿
    - 补偿铺放头与示教铺放头的重量与重心位置，以及六维力传感器的零偏
- 示教数据采集节点
    - 采集示教器末端位姿、末端力传感器数据、相机点云数据
    - 保存为rosbag文件



## 采集前

### 手眼标定
手眼标定请参考[手眼标定](src/il_capture/calibrate/手眼标定.md)

### 机械臂与动作捕捉系统标定

1. 在机械臂末端安装贴上动捕点的标定物，在机械臂示教器中设置好动捕点的TCP位置
2. 在`data`文件夹下新建csv文件，名为`calib_frange_nokov.csv`，内容如下：

   | id|pointx|pointy|pointz|toolx|tooly|toolz|
   |----------|------|------|------|------|------|------|
   | 0        |      |      |      |      |      |      |
   | 1        |      |      |      |      |      |      |
3. 启动机械臂驱动和动作捕捉系统，移动机械臂，并记录动捕点在动捕系统中的位置与示教器上的TCP位置，填写到`calib_frange_nokov.csv`中， pointx、pointy、pointz为动捕点在动捕系统中的位置，toolx、tooly、toolz为示教器上TCP位置
4. 运行标定节点
   ```
   python src/il_capture/scripts/calib_sth&nokov.ipynb
   ```
5. 结果保存在`T_robot_to_mocap.txt`中

### 重力补偿

#### 看上去很牛逼但是没办法用
1. 启动重力补偿节点
   ```
   roslaunch il_capture tare_calibration.launch
   ```

2. 按照提示操作，缓慢变换示教器末端姿态，采集数据
3. 结果保存在`config/capture_config.yaml`中

#### 简单粗暴版
1. 将示教器放在机械臂末端
2. 将末端调整至重力沿着坐标系XYZ轴任一轴的正/负方向，共6个姿态，然后使用[get_average_force.py](scripts/temp/get_average_force.py)记录当前姿态的力传感器读数，填入csv文件，csv文件格式要求如下：
   | pose | fx | fy | fz | tx | ty | tz |
   |---------|----|----|----|----|----|----|
   | z_down       |    |    |    |    |    |    |
   | z_up       |    |    |    |    |    |    |
   | x_down       |    |    |    |    |    |    |
   | x_up       |    |    |    |    |    |    |
   | y_down       |    |    |    |    |    |    |
   | y_up       |    |    |    |    |    |    |
3. 运行[pure_gravity_tare.py](scripts/pure_gravity_tare.py)进行重力补偿计算，将结果填入`config/capture_config.yaml`中
4. 由于力传感器存在严重的零偏漂移问题，每次采集数据前，让传感器与负载保持一已知姿态静止一段时间，减去保存的该负载的重力，以减小零偏漂移的影响
- todo: 将该功能写成规范化流程脚本

### 整合标定内容
将`T_robot_to_mocap.txt`内的矩阵复制到`config/capture_config.yaml`，
eg：
```
T_robot_to_mocap:
- [0.999880, 0.015185, -0.003222, 0.576824]
- [-0.015229, 0.999783, -0.014241, 1.881803]
- [0.003005, 0.014289, 0.999893, 0.787360]
- [0.000000, 0.000000, 0.000000, 1.000000]
```
将`result_hand_eye.txt`内的矩阵复制到`config/capture_config.yaml`，
eg：
```
T_cam_to_robot:
- [0.99792915, -0.03649027, 0.05297047, -0.49098128]
- [-0.05750444, -0.87510496, 0.48050448, -0.60853754]
- [0.02882098, -0.48255546, -0.87539110, 0.50756379]
- [0.00000000, 0.00000000, 0.00000000, 1.00000000]
```

并补充以下内容:
```
T_ee_to_tool:
- [1.000000, 0.000000, 0.000000, 0.000000]
- [0.000000, 1.000000, 0.000000, 0.090000]
- [0.000000, 0.000000, 1.000000, 0.237000] 
- [0.000000, 0.000000, 0.000000, 1.000000]

T_sensor_to_ee:
- [1.000000, 0.000000, 0.000000, 0.000000]
- [0.000000, 1.000000, 0.000000, 0.000000]
- [0.000000, 0.000000, 1.000000, 0.000000]
- [0.000000, 0.000000, 0.000000, 1.000000]
```
其中`T_ee_to_tool`为示教器末端到工具坐标系的变换矩阵，`T_sensor_to_ee`为力传感器到示教器末端的变换矩阵，根据实际情况修改

## 示教数据采集
1. 启动以下节点
    ```
    roslaunch il_capture capture_device_bringup.launch
    roslaunch il_capture capture_task.launch
    ```
2. 数据将以hdf5格式保存在`data`文件夹下, 以及保存为rosbag文件在`data/rosbag`文件夹下

## 示教数据后处理
TODO: 考虑在采集时采集原始数据，在采集完成后再进行坐标变换等处理，目前是在采集时就进行处理并保存处理后的数据
